# ğŸ† Results

This document captures **all** experimental outcomes in one place.  
Every modelâ€‘variant gets its own subsection containing:

* **Perâ€‘publication scores** â€“ 1,000 heldâ€‘out articles for **each** of the ten sources.  
  `Publication | Accuracy | Precision | Recall |Â F1`
* **Topâ€‘line scores** â€“ aggregate metrics on the full 10,000â€‘article test set.

> â„¹ï¸ **How to use this file:**  
> 1. Run your experiment.  
> 2. Paste the metrics into the matching table below (replace the `â€”` dashes).  
> 3. Commit the updatedÂ `results.md` so future readers can compare techniques at a glance.

---

## Dataset at a Glance
| Split | Articles | Perâ€‘Class Balance |
|-------|----------|-------------------|
| Train | 90,000   | 9,000 each        |
| Test  | 10,000   | 1,000 each        |

<sub>Totals: **100,000** articles, 10 labels, perfectly stratified.</sub>

---

## BaselineÂ ğŸ“‰ Â (UniformÂ RandomÂ â€”Â â€œrollÂ aÂ d10â€)

| Metric | Value |
|--------|-------|
| FitÂ time (s) | **0.036** |
| ScoreÂ time (s) | **0.220** |
| Accuracy | **0.1018** |
| PrecisionÂ (macro) | **0.1018** |
| RecallÂ (macro) | **0.1018** |
| F1Â (macro) | **0.1018** |

*No perâ€‘class table is necessary â€“ every label is hit ~10Â % of the time by chance.*

---

# 1Â Â Classic MethodsÂ ğŸ§®
## 1.1Â Bagâ€‘ofâ€‘WordsÂ (BOW)

### 1.1.1Â MultinomialÂ NaÃ¯veÂ Bayes
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | â€” | â€” | â€” |
| FoxÂ News | â€” | â€” | â€” | â€” |
| CNN | â€” | â€” | â€” | â€” |
| Reuters | â€” | â€” | â€” | â€” |
| Vice | â€” | â€” | â€” | â€” |
| TheÂ NewÂ YorkÂ Times | â€” | â€” | â€” | â€” |
| Politico | â€” | â€” | â€” | â€” |
| TheÂ Hill | â€” | â€” | â€” | â€” |
| TheÂ Economist | â€” | â€” | â€” | â€” |
| People | â€” | â€” | â€” | â€” |
| **Topâ€‘Line** | â€” | â€” | â€” | â€” |

### 1.1.2Â LinearÂ SVM (BOWÂ features)
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | â€” | â€” | â€” |
| FoxÂ News | â€” | â€” | â€” | â€” |
| CNN | â€” | â€” | â€” | â€” |
| Reuters | â€” | â€” | â€” | â€” |
| Vice | â€” | â€” | â€” | â€” |
| TheÂ NewÂ YorkÂ Times | â€” | â€” | â€” | â€” |
| Politico | â€” | â€” | â€” | â€” |
| TheÂ Hill | â€” | â€” | â€” | â€” |
| TheÂ Economist | â€” | â€” | â€” | â€” |
| People | â€” | â€” | â€” | â€” |
| **Topâ€‘Line** | â€” | â€” | â€” | â€” |

---

## 1.2Â Word2Vec Averages

### 1.2.1Â LogisticÂ Regression
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | â€” | â€” | â€” |
| FoxÂ News | â€” | â€” | â€” | â€” |
| CNN | â€” | â€” | â€” | â€” |
| Reuters | â€” | â€” | â€” | â€” |
| Vice | â€” | â€” | â€” | â€” |
| TheÂ NewÂ YorkÂ Times | â€” | â€” | â€” | â€” |
| Politico | â€” | â€” | â€” | â€” |
| TheÂ Hill | â€” | â€” | â€” | â€” |
| TheÂ Economist | â€” | â€” | â€” | â€” |
| People | â€” | â€” | â€” | â€” |
| **Topâ€‘Line** | â€” | â€” | â€” | â€” |

### 1.2.2Â SVM (RBFÂ KernelÂ +Â W2V)
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | â€” | â€” | â€” |
| FoxÂ News | â€” | â€” | â€” | â€” |
| CNN | â€” | â€” | â€” | â€” |
| Reuters | â€” | â€” | â€” | â€” |
| Vice | â€” | â€” | â€” | â€” |
| TheÂ NewÂ YorkÂ Times | â€” | â€” | â€” | â€” |
| Politico | â€” | â€” | â€” | â€” |
| TheÂ Hill | â€” | â€” | â€” | â€” |
| TheÂ Economist | â€” | â€” | â€” | â€” |
| People | â€” | â€” | â€” | â€” |
| **Topâ€‘Line** | â€” | â€” | â€” | â€” |

---

#Â 2Â Â NeuralÂ MethodsÂ ğŸ§ 
## 2.1Â 1â€‘D ConvolutionalÂ NeuralÂ NetworkÂ (CNNâ€‘Text)
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | â€” | â€” | â€” |
| FoxÂ News | â€” | â€” | â€” | â€” |
| CNN | â€” | â€” | â€” | â€” |
| Reuters | â€” | â€” | â€” | â€” |
| Vice | â€” | â€” | â€” | â€” |
| TheÂ NewÂ YorkÂ Times | â€” | â€” | â€” | â€” |
| Politico | â€” | â€” | â€” | â€” |
| TheÂ Hill | â€” | â€” | â€” | â€” |
| TheÂ Economist | â€” | â€” | â€” | â€” |
| People | â€” | â€” | â€” | â€” |
| **Topâ€‘Line** | â€” | â€” | â€” | â€” |

## 2.2Â Feedâ€‘Forward NeuralÂ NetworkÂ (FFNN)
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | 0.50 | 0.55 | 0.53 |
| FoxÂ News | â€” | 0.63 | 0.54 | 0.58 |
| CNN | â€” | 0.64 | 0.48 | 0.55 |
| Reuters | â€” | 0.79 | 0.89 | 0.84 |
| Vice | â€” | 0.83 | 0.75 | 0.79 |
| TheÂ NewÂ YorkÂ Times | â€” | 0.69 | 0.70 | 0.70 |
| Politico | â€” | 0.61 | 0.68 | 0.64 |
| TheÂ Hill | â€” | 0.84 | 0.79 | 0.81 |
| TheÂ Economist | â€” | 0.90 | 0.95 | 0.93 |
| People | â€” | 0.74 | 0.84 | 0.79 |
| **Topâ€‘Line** | 0.72 | 0.72 | 0.72 | 0.71 |

---

#Â 3Â Â Ruleâ€‘BasedÂ ApproachÂ âœï¸ (Editorial StyleÂ GuideÂ Rules)
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | â€” | â€” | â€” |
| FoxÂ News | â€” | â€” | â€” | â€” |
| CNN | â€” | â€” | â€” | â€” |
| Reuters | â€” | â€” | â€” | â€” |
| Vice | â€” | â€” | â€” | â€” |
| TheÂ NewÂ YorkÂ Times | â€” | â€” | â€” | â€” |
| Politico | â€” | â€” | â€” | â€” |
| TheÂ Hill | â€” | â€” | â€” | â€” |
| TheÂ Economist | â€” | â€” | â€” | â€” |
| People | â€” | â€” | â€” | â€” |
| **Topâ€‘Line** | â€” | â€” | â€” | â€” |

---

#Â 4Â Â LargeÂ LanguageÂ ModelÂ (LLM)Â âš¡
## 4.1Â Mistralâ€‘7BÂ (0â€‘shot, system prompt = *â€œPredict publisherâ€*)
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | â€” | â€” | â€” |
| FoxÂ News | â€” | â€” | â€” | â€” |
| CNN | â€” | â€” | â€” | â€” |
| Reuters | â€” | â€” | â€” | â€” |
| Vice | â€” | â€” | â€” | â€” |
| TheÂ NewÂ YorkÂ Times | â€” | â€” | â€” | â€” |
| Politico | â€” | â€” | â€” | â€” |
| TheÂ Hill | â€” | â€” | â€” | â€” |
| TheÂ Economist | â€” | â€” | â€” | â€” |
| People | â€” | â€” | â€” | â€” |
| **Topâ€‘Line** | â€” | â€” | â€” | â€” |

---

#Â 5Â Â Transformerâ€‘BasedÂ EncodersÂ ğŸ¦¾
## 5.1Â BERTÂ (Base, uncased)Â +Â [CLS]Â Logistic Head
| Publication | Accuracy | Precision | Recall | F1 |
|-------------|----------|-----------|--------|----|
| BuzzFeedÂ News | â€” | â€” | â€” | â€” |
| FoxÂ News | â€” | â€” | â€” | â€” |
| CNN | â€” | â€” | â€” | â€” |
| Reuters | â€” | â€” | â€” | â€” |
| Vice | â€” | â€” | â€” | â€” |
| TheÂ NewÂ YorkÂ Times | â€” | â€” | â€” | â€” |
| Politico | â€” | â€” | â€” | â€” |
| TheÂ Hill | â€” | â€” | â€” | â€” |
| TheÂ Economist | â€” | â€” | â€” | â€” |
| People | â€” | â€” | â€” | â€” |
| **Topâ€‘Line** | â€” | â€” | â€” | â€” |

---

## ğŸ“ŒÂ NextÂ Steps
1. **Run** an experiment.  
2. **Replace** the `â€”` placeholders with real numbers (keep three decimals).  
3. **Add** notes under the table if hyperâ€‘parameters or tricks are critical.  