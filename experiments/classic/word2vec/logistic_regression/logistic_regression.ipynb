{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas scikit-learn gensim nltk tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hunterschep/.pyenv/versions/3.12.5/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec, Phrases, phrases\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing, warnings, re, string, os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          publication                                      clean_article  \\\n",
      "0  The New York Times   a love of [NAME] and slap bracelets, [NAME] s...   \n",
      "1  The New York Times  warm, occasionally downright balmy, weather, a...   \n",
      "2  The New York Times  dably confused. When he was a boy, Havana was ...   \n",
      "\n",
      "   split  \n",
      "0  train  \n",
      "1  train  \n",
      "2  train  \n",
      "Train rows: 90,000  •  Test rows: 10,000\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../../../../data/all-the-news-2-1-SMALL-CLEANED.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.head(3)[[\"publication\", \"clean_article\", \"split\"]])\n",
    "\n",
    "# Split provided by the file\n",
    "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train rows: {len(train_df):,}  •  Test rows: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90000/90000 [00:10<00:00, 8598.52it/s] \n"
     ]
    }
   ],
   "source": [
    "def simple_tokenizer(text: str):\n",
    "    text = text.lower()\n",
    "    # remove punctuation but keep intra‑word ’ characters if any\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    return wordpunct_tokenize(text)\n",
    "\n",
    "# Tokenize every article (lazy eval with progress bar)\n",
    "train_tokens = train_df[\"clean_article\"].progress_map(simple_tokenizer)\n",
    "test_tokens  = test_df[\"clean_article\"].map(simple_tokenizer)\n",
    "\n",
    "# Learn bigram phrases from training corpus\n",
    "bigram_phrases = Phrases(train_tokens, min_count=5, threshold=10)\n",
    "bigram_phraser = phrases.Phraser(bigram_phrases)\n",
    "\n",
    "# Apply bigrams\n",
    "train_tokens = train_tokens.apply(lambda x: bigram_phraser[x])\n",
    "test_tokens  = test_tokens.apply(lambda x: bigram_phraser[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Word2Vec epochs: 100%|██████████| 10/10 [03:54<00:00, 23.44s/it, loss=70370616.00]\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM  = 200        # vector size\n",
    "WINDOW     = 5\n",
    "MIN_COUNT  = 3\n",
    "SG         = 1          # 1 = skip‑gram, 0 = CBOW\n",
    "EPOCHS     = 10\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    \"\"\"Logs loss & shows a tqdm bar for each epoch.\"\"\"\n",
    "    def __init__(self, total_epochs):\n",
    "        self.epoch     = 0\n",
    "        self.pbar      = tqdm(total=total_epochs, desc=\"Word2Vec epochs\")\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        self.pbar.set_postfix({\"loss\": f\"{loss:.2f}\"})\n",
    "        self.pbar.update(1)\n",
    "        self.epoch += 1\n",
    "        if self.epoch == self.pbar.total:\n",
    "            self.pbar.close()\n",
    "\n",
    "logger = EpochLogger(EPOCHS)\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=list(train_tokens),\n",
    "    vector_size=EMBED_DIM,\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    workers=multiprocessing.cpu_count() - 1,\n",
    "    sg=SG,\n",
    "    epochs=EPOCHS,\n",
    "    compute_loss=True,      # required to query loss\n",
    "    callbacks=[logger],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90000/90000 [00:29<00:00, 3057.06it/s]\n",
      "100%|██████████| 10000/10000 [00:03<00:00, 2916.63it/s]\n"
     ]
    }
   ],
   "source": [
    "def sent_vector(tokens, model, dim):\n",
    "    \"\"\"Average the word vectors for tokens present in the model’s vocab.\n",
    "       Returns a zero‑vector if no token is in the vocab.\"\"\"\n",
    "    valid_vecs = [model.wv[t] for t in tokens if t in model.wv]\n",
    "    if not valid_vecs:\n",
    "        return np.zeros(dim)\n",
    "    return np.mean(valid_vecs, axis=0)\n",
    "\n",
    "# Vectorize train & test articles\n",
    "X_train = np.vstack([sent_vector(tok, w2v_model, EMBED_DIM) for tok in tqdm(train_tokens)])\n",
    "X_test  = np.vstack([sent_vector(tok, w2v_model, EMBED_DIM) for tok in tqdm(test_tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()\n",
    "y_train = lbl.fit_transform(train_df[\"publication\"])\n",
    "y_test  = lbl.transform(test_df[\"publication\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 14 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➜ fitting multinomial logistic regression …\n",
      "Epoch 1, change: 1\n",
      "Epoch 2, change: 0.22528766\n",
      "Epoch 3, change: 0.10609978\n",
      "Epoch 4, change: 0.064357772\n",
      "Epoch 5, change: 0.037169386\n",
      "Epoch 6, change: 0.027772887\n",
      "Epoch 7, change: 0.021195205\n",
      "Epoch 8, change: 0.016564978\n",
      "Epoch 9, change: 0.011365883\n",
      "Epoch 10, change: 0.0095630484\n",
      "Epoch 11, change: 0.0078384262\n",
      "Epoch 12, change: 0.0067749382\n",
      "Epoch 13, change: 0.0060203695\n",
      "Epoch 14, change: 0.0054770941\n",
      "Epoch 15, change: 0.0049634045\n",
      "Epoch 16, change: 0.0046122763\n",
      "Epoch 17, change: 0.0043170792\n",
      "Epoch 18, change: 0.0040159337\n",
      "Epoch 19, change: 0.0037848926\n",
      "Epoch 20, change: 0.0036282705\n",
      "Epoch 21, change: 0.0033824567\n",
      "Epoch 22, change: 0.0031073925\n",
      "Epoch 23, change: 0.0028573468\n",
      "Epoch 24, change: 0.0026119046\n",
      "Epoch 25, change: 0.0024275014\n",
      "Epoch 26, change: 0.0022909422\n",
      "Epoch 27, change: 0.0021519039\n",
      "Epoch 28, change: 0.0020571619\n",
      "Epoch 29, change: 0.0019627516\n",
      "Epoch 30, change: 0.0017946761\n",
      "Epoch 31, change: 0.0017236859\n",
      "Epoch 32, change: 0.001597615\n",
      "Epoch 33, change: 0.0015067384\n",
      "Epoch 34, change: 0.0013997188\n",
      "Epoch 35, change: 0.0013567593\n",
      "Epoch 36, change: 0.001239941\n",
      "Epoch 37, change: 0.0011476548\n",
      "Epoch 38, change: 0.0010462571\n",
      "Epoch 39, change: 0.00093073625\n",
      "Epoch 40, change: 0.00085914234\n",
      "Epoch 41, change: 0.00079098775\n",
      "Epoch 42, change: 0.00072962599\n",
      "Epoch 43, change: 0.00066612888\n",
      "Epoch 44, change: 0.00060622208\n",
      "Epoch 45, change: 0.00055824913\n",
      "Epoch 46, change: 0.0005501085\n",
      "Epoch 47, change: 0.00049767515\n",
      "Epoch 48, change: 0.00044742829\n",
      "Epoch 49, change: 0.00042873065\n",
      "Epoch 50, change: 0.00038982456\n",
      "Epoch 51, change: 0.00037601116\n",
      "Epoch 52, change: 0.00036373615\n",
      "Epoch 53, change: 0.00033612573\n",
      "Epoch 54, change: 0.00032511339\n",
      "Epoch 55, change: 0.00028863715\n",
      "Epoch 56, change: 0.00029858635\n",
      "Epoch 57, change: 0.00027924677\n",
      "Epoch 58, change: 0.00032160903\n",
      "Epoch 59, change: 0.00029525542\n",
      "Epoch 60, change: 0.00027150477\n",
      "Epoch 61, change: 0.00023311742\n",
      "Epoch 62, change: 0.00021702336\n",
      "Epoch 63, change: 0.00020258682\n",
      "Epoch 64, change: 0.00019654664\n",
      "Epoch 65, change: 0.00020125962\n",
      "Epoch 66, change: 0.00017465295\n",
      "Epoch 67, change: 0.00020132841\n",
      "Epoch 68, change: 0.00017084024\n",
      "Epoch 69, change: 0.00018813385\n",
      "Epoch 70, change: 0.0002009468\n",
      "Epoch 71, change: 0.00018744102\n",
      "Epoch 72, change: 0.00017181387\n",
      "Epoch 73, change: 0.00014023215\n",
      "Epoch 74, change: 0.00016490286\n",
      "Epoch 75, change: 0.00014264535\n",
      "Epoch 76, change: 0.000145563\n",
      "Epoch 77, change: 0.00016799477\n",
      "Epoch 78, change: 0.00011542266\n",
      "Epoch 79, change: 0.00012722875\n",
      "Epoch 80, change: 0.00015334036\n",
      "Epoch 81, change: 0.00014833949\n",
      "Epoch 82, change: 0.00014097898\n",
      "Epoch 83, change: 0.00013896496\n",
      "Epoch 84, change: 0.00023810154\n",
      "Epoch 85, change: 0.00013333978\n",
      "Epoch 86, change: 0.00016403483\n",
      "Epoch 87, change: 0.00012195011\n",
      "Epoch 88, change: 0.00023556531\n",
      "Epoch 89, change: 0.00014844417\n",
      "Epoch 90, change: 0.0002281357\n",
      "Epoch 91, change: 0.0001274352\n",
      "Epoch 92, change: 0.00013507533\n",
      "Epoch 93, change: 0.00021573728\n",
      "Epoch 94, change: 0.00013222768\n",
      "Epoch 95, change: 0.0001529752\n",
      "Epoch 96, change: 0.00015281922\n",
      "Epoch 97, change: 0.00016674276\n",
      "Epoch 98, change: 0.00013906883\n",
      "Epoch 99, change: 0.00013708867\n",
      "Epoch 100, change: 0.00014146356\n",
      "Epoch 101, change: 0.0001426785\n",
      "Epoch 102, change: 0.0001929241\n",
      "Epoch 103, change: 0.00019125706\n",
      "Epoch 104, change: 0.00015705424\n",
      "Epoch 105, change: 0.00021389659\n",
      "Epoch 106, change: 0.00014573633\n",
      "Epoch 107, change: 0.00016695254\n",
      "Epoch 108, change: 0.00019712743\n",
      "Epoch 109, change: 0.00014104816\n",
      "Epoch 110, change: 0.00013549253\n",
      "Epoch 111, change: 0.00020025659\n",
      "Epoch 112, change: 0.00011618801\n",
      "Epoch 113, change: 0.00014500869\n",
      "Epoch 114, change: 0.00019567017\n",
      "Epoch 115, change: 0.00013715988\n",
      "Epoch 116, change: 0.0001640371\n",
      "Epoch 117, change: 0.00019400258\n",
      "Epoch 118, change: 0.00011139452\n",
      "Epoch 119, change: 0.00012288793\n",
      "Epoch 120, change: 0.00019379561\n",
      "Epoch 121, change: 0.00010799213\n",
      "Epoch 122, change: 0.00015514917\n",
      "Epoch 123, change: 0.00018956036\n",
      "Epoch 124, change: 0.00015278719\n",
      "Epoch 125, change: 0.00010865371\n",
      "Epoch 126, change: 0.00019195695\n",
      "Epoch 127, change: 0.0001178203\n",
      "Epoch 128, change: 0.00015098142\n",
      "Epoch 129, change: 0.00018956012\n",
      "Epoch 130, change: 0.00014313337\n",
      "Epoch 131, change: 0.00015386409\n",
      "Epoch 132, change: 0.00019456078\n",
      "Epoch 133, change: 0.0001166736\n",
      "Epoch 134, change: 0.00011775015\n",
      "Epoch 135, change: 0.00013125753\n",
      "Epoch 136, change: 0.00018348216\n",
      "Epoch 137, change: 0.00014653552\n",
      "Epoch 138, change: 0.000129138\n",
      "Epoch 139, change: 0.00014841075\n",
      "Epoch 140, change: 0.00017407459\n",
      "Epoch 141, change: 0.00013646786\n",
      "Epoch 142, change: 0.00012625755\n",
      "Epoch 143, change: 0.0001835874\n",
      "Epoch 144, change: 0.00011854871\n",
      "Epoch 145, change: 0.00013584063\n",
      "Epoch 146, change: 0.00013948648\n",
      "Epoch 147, change: 0.00013677751\n",
      "Epoch 148, change: 0.00012910392\n",
      "Epoch 149, change: 0.00019056484\n",
      "Epoch 150, change: 0.00013854842\n",
      "Epoch 151, change: 0.0001757757\n",
      "Epoch 152, change: 0.00014723232\n",
      "Epoch 153, change: 0.00017046134\n",
      "Epoch 154, change: 0.00014289051\n",
      "Epoch 155, change: 0.00012865356\n",
      "Epoch 156, change: 0.00018487209\n",
      "Epoch 157, change: 0.00015723154\n",
      "Epoch 158, change: 0.00013851501\n",
      "Epoch 159, change: 0.00014507951\n",
      "Epoch 160, change: 0.00017484212\n",
      "Epoch 161, change: 0.0001396642\n",
      "Epoch 162, change: 0.00014622827\n",
      "Epoch 163, change: 0.00014108788\n",
      "Epoch 164, change: 0.00013938596\n",
      "Epoch 165, change: 0.00014032357\n",
      "Epoch 166, change: 0.0001190733\n",
      "Epoch 167, change: 0.00013153988\n",
      "Epoch 168, change: 0.00013563599\n",
      "Epoch 169, change: 0.00012184967\n",
      "Epoch 170, change: 0.00017466696\n",
      "Epoch 171, change: 0.0001454975\n",
      "Epoch 172, change: 0.0001699799\n",
      "Epoch 173, change: 0.00014372707\n",
      "Epoch 174, change: 0.00013806605\n",
      "Epoch 175, change: 0.00011993901\n",
      "Epoch 176, change: 0.00018015108\n",
      "Epoch 177, change: 0.00013528655\n",
      "Epoch 178, change: 0.00016896862\n",
      "Epoch 179, change: 0.00013952238\n",
      "Epoch 180, change: 0.00011396663\n",
      "Epoch 181, change: 0.0001794917\n",
      "Epoch 182, change: 0.00013101478\n",
      "Epoch 183, change: 0.00016726714\n",
      "Epoch 184, change: 0.00014386402\n",
      "Epoch 185, change: 0.00012348109\n",
      "Epoch 186, change: 0.0001854674\n",
      "Epoch 187, change: 0.00012806513\n",
      "Epoch 188, change: 0.00017129657\n",
      "Epoch 189, change: 0.00013730065\n",
      "Epoch 190, change: 0.00013087881\n",
      "Epoch 191, change: 0.00017678829\n",
      "Epoch 192, change: 0.00013522012\n",
      "Epoch 193, change: 0.00014622828\n",
      "Epoch 194, change: 0.00016122857\n",
      "Epoch 195, change: 0.00014160859\n",
      "Epoch 196, change: 0.00011021682\n",
      "Epoch 197, change: 0.00017987384\n",
      "Epoch 198, change: 0.00012511289\n",
      "Epoch 199, change: 0.00012240624\n",
      "Epoch 200, change: 0.00016872822\n",
      "Epoch 201, change: 0.00014615596\n",
      "Epoch 202, change: 0.00013025192\n",
      "Epoch 203, change: 0.00013094851\n",
      "Epoch 204, change: 0.00017310734\n",
      "Epoch 205, change: 0.00013734182\n",
      "Epoch 206, change: 0.00011577779\n",
      "Epoch 207, change: 0.00018449944\n",
      "Epoch 208, change: 0.00014744485\n",
      "Epoch 209, change: 0.00016786346\n",
      "Epoch 210, change: 0.00013858872\n",
      "Epoch 211, change: 0.00011851866\n",
      "Epoch 212, change: 0.00017650989\n",
      "Epoch 213, change: 0.00013612339\n",
      "Epoch 214, change: 0.00015279368\n",
      "Epoch 215, change: 0.00015897621\n",
      "Epoch 216, change: 0.00013373233\n",
      "Epoch 217, change: 0.00017668995\n",
      "Epoch 218, change: 0.00013953094\n",
      "Epoch 219, change: 0.00013935812\n",
      "Epoch 220, change: 0.00014039944\n",
      "Epoch 221, change: 0.00014956734\n",
      "Epoch 222, change: 0.00018182679\n",
      "Epoch 223, change: 0.00014128245\n",
      "Epoch 224, change: 0.00014734082\n",
      "Epoch 225, change: 0.0001744601\n",
      "Epoch 226, change: 0.00013254829\n",
      "Epoch 227, change: 0.00011379767\n",
      "Epoch 228, change: 0.00018137637\n",
      "Epoch 229, change: 0.00011654113\n",
      "Epoch 230, change: 0.00013018957\n",
      "Epoch 231, change: 0.00018429525\n",
      "Epoch 232, change: 0.00014880233\n",
      "Epoch 233, change: 0.00016724075\n",
      "Epoch 234, change: 0.00013914896\n",
      "Epoch 235, change: 0.00015015884\n",
      "Epoch 236, change: 0.00018203814\n",
      "Epoch 237, change: 0.00012761974\n",
      "Epoch 238, change: 0.00017137318\n",
      "Epoch 239, change: 0.00014011965\n",
      "Epoch 240, change: 0.00013390223\n",
      "Epoch 241, change: 0.00018342327\n",
      "Epoch 242, change: 0.00010983969\n",
      "Epoch 243, change: 0.00011348617\n",
      "Epoch 244, change: 0.00018373587\n",
      "Epoch 245, change: 0.00014383408\n",
      "Epoch 246, change: 0.00010810203\n",
      "Epoch 247, change: 0.00016828509\n",
      "Epoch 248, change: 0.00016442993\n",
      "Epoch 249, change: 0.00013074456\n",
      "Epoch 250, change: 0.00011557016\n",
      "Epoch 251, change: 0.00018891355\n",
      "Epoch 252, change: 0.00013435606\n",
      "Epoch 253, change: 0.00016620166\n",
      "Epoch 254, change: 0.00013453308\n",
      "Epoch 255, change: 0.00013946545\n",
      "Epoch 256, change: 0.00018343113\n",
      "Epoch 257, change: 0.00014064499\n",
      "Epoch 258, change: 0.00010491112\n",
      "Epoch 259, change: 0.00017071878\n",
      "Epoch 260, change: 0.00013501781\n",
      "Epoch 261, change: 0.00015939496\n",
      "Epoch 262, change: 0.00018415602\n",
      "Epoch 263, change: 0.00013623394\n",
      "Epoch 264, change: 0.0001443611\n",
      "Epoch 265, change: 0.000133284\n",
      "Epoch 266, change: 0.00014158436\n",
      "Epoch 267, change: 0.00016898497\n",
      "Epoch 268, change: 0.00013898089\n",
      "Epoch 269, change: 0.00016683321\n",
      "Epoch 270, change: 0.00013450019\n",
      "Epoch 271, change: 0.00013088585\n",
      "Epoch 272, change: 0.00018321788\n",
      "Epoch 273, change: 0.00011831488\n",
      "Epoch 274, change: 0.00012588626\n",
      "Epoch 275, change: 0.00018381234\n",
      "Epoch 276, change: 0.00014564689\n",
      "Epoch 277, change: 0.00017221198\n",
      "Epoch 278, change: 0.00012550493\n",
      "Epoch 279, change: 0.00011887088\n",
      "Epoch 280, change: 0.00023274284\n",
      "Epoch 281, change: 0.00014217434\n",
      "Epoch 282, change: 0.00013786844\n",
      "Epoch 283, change: 0.00018746076\n",
      "Epoch 284, change: 0.00013773206\n",
      "Epoch 285, change: 0.00017214732\n",
      "Epoch 286, change: 0.00014346103\n",
      "Epoch 287, change: 0.00011554073\n",
      "Epoch 288, change: 0.00017676754\n",
      "Epoch 289, change: 0.00012429286\n",
      "Epoch 290, change: 0.00017214844\n",
      "Epoch 291, change: 0.00012932667\n",
      "Epoch 292, change: 0.00015242147\n",
      "Epoch 293, change: 0.00016700718\n",
      "Epoch 294, change: 0.00012248443\n",
      "Epoch 295, change: 0.00014731598\n",
      "Epoch 296, change: 0.00017745922\n",
      "Epoch 297, change: 0.00013727928\n",
      "Epoch 298, change: 0.00016676488\n",
      "Epoch 299, change: 0.00013856628\n",
      "Epoch 300, change: 0.00012300782\n",
      "Epoch 301, change: 0.00017555346\n",
      "Epoch 302, change: 0.00012515968\n",
      "Epoch 303, change: 0.00012720912\n",
      "Epoch 304, change: 0.00017940253\n",
      "Epoch 305, change: 0.00015235042\n",
      "Epoch 306, change: 0.00017096275\n",
      "Epoch 307, change: 0.00014036805\n",
      "Epoch 308, change: 0.00010692648\n",
      "Epoch 309, change: 0.00018211333\n",
      "Epoch 310, change: 0.00014255817\n",
      "Epoch 311, change: 0.00013637665\n",
      "Epoch 312, change: 0.00018082582\n",
      "Epoch 313, change: 0.00011890494\n",
      "Epoch 314, change: 0.00016578392\n",
      "Epoch 315, change: 0.00014078243\n",
      "Epoch 316, change: 0.00014060935\n",
      "Epoch 317, change: 0.00018221496\n",
      "Epoch 318, change: 0.00012071266\n",
      "Epoch 319, change: 0.0001447103\n",
      "Epoch 320, change: 0.00014012658\n",
      "Epoch 321, change: 0.00013116701\n",
      "Epoch 322, change: 0.00012390724\n",
      "Epoch 323, change: 0.00012814498\n",
      "Epoch 324, change: 0.0001843333\n",
      "Epoch 325, change: 0.0001148423\n",
      "Epoch 326, change: 0.00012324746\n",
      "Epoch 327, change: 0.00018235462\n",
      "Epoch 328, change: 0.00013561192\n",
      "Epoch 329, change: 0.00016839488\n",
      "Epoch 330, change: 0.00013637682\n",
      "Epoch 331, change: 0.00012384032\n",
      "Epoch 332, change: 0.00020850655\n",
      "Epoch 333, change: 0.00012661649\n",
      "Epoch 334, change: 0.00013234725\n",
      "Epoch 335, change: 0.00018589798\n",
      "Epoch 336, change: 0.00014405169\n",
      "Epoch 337, change: 0.00012839022\n",
      "Epoch 338, change: 0.00018836552\n",
      "Epoch 339, change: 0.00014759217\n",
      "Epoch 340, change: 0.00017304963\n",
      "Epoch 341, change: 0.00013342492\n",
      "Epoch 342, change: 0.00010800525\n",
      "Epoch 343, change: 0.00012193049\n",
      "Epoch 344, change: 0.00017343376\n",
      "Epoch 345, change: 0.00014679758\n",
      "Epoch 346, change: 0.0001482209\n",
      "Epoch 347, change: 0.00018124739\n",
      "Epoch 348, change: 0.00013835837\n",
      "Epoch 349, change: 0.000166767\n",
      "Epoch 350, change: 0.00012016108\n",
      "Epoch 351, change: 0.00011818208\n",
      "Epoch 352, change: 0.0001214119\n",
      "Epoch 353, change: 0.00013988526\n",
      "Epoch 354, change: 0.00015884811\n",
      "Epoch 355, change: 0.00014408906\n",
      "Epoch 356, change: 0.00012287038\n",
      "Epoch 357, change: 0.00017791445\n",
      "Epoch 358, change: 0.00012783434\n",
      "Epoch 359, change: 0.0001664525\n",
      "Epoch 360, change: 0.00014898423\n",
      "Epoch 361, change: 0.00011186007\n",
      "Epoch 362, change: 0.00017798362\n",
      "Epoch 363, change: 0.00017225408\n",
      "Epoch 364, change: 0.00016186996\n",
      "Epoch 365, change: 0.00014224905\n",
      "Epoch 366, change: 0.00013636242\n",
      "Epoch 367, change: 0.0001805209\n",
      "Epoch 368, change: 0.00011856414\n",
      "Epoch 369, change: 0.00017017107\n",
      "Epoch 370, change: 0.00014565318\n",
      "Epoch 371, change: 0.0001236005\n",
      "Epoch 372, change: 0.00017770767\n",
      "Epoch 373, change: 0.00013457444\n",
      "Epoch 374, change: 0.00016590075\n",
      "Epoch 375, change: 0.00013811729\n",
      "Epoch 376, change: 0.00013742241\n",
      "Epoch 377, change: 0.0002395608\n",
      "Epoch 378, change: 0.00013179632\n",
      "Epoch 379, change: 0.00013224722\n",
      "Epoch 380, change: 0.00018041431\n",
      "Epoch 381, change: 0.0001233214\n",
      "Epoch 382, change: 0.00013351452\n",
      "Epoch 383, change: 0.00018249986\n",
      "Epoch 384, change: 0.00011363228\n",
      "Epoch 385, change: 0.00016468146\n",
      "Epoch 386, change: 0.00012068146\n",
      "Epoch 387, change: 0.00018204574\n",
      "Epoch 388, change: 0.00012585547\n",
      "Epoch 389, change: 0.00012373638\n",
      "Epoch 390, change: 0.00014085814\n",
      "Epoch 391, change: 0.00016794632\n",
      "Epoch 392, change: 0.00012189672\n",
      "Epoch 393, change: 0.00023511167\n",
      "Epoch 394, change: 0.00017353903\n",
      "Epoch 395, change: 0.00013537236\n",
      "Epoch 396, change: 0.00014273467\n",
      "Epoch 397, change: 0.00018482738\n",
      "Epoch 398, change: 0.00012630892\n",
      "Epoch 399, change: 0.00017048424\n",
      "Epoch 400, change: 0.00013519714\n",
      "Epoch 401, change: 0.00015023572\n",
      "Epoch 402, change: 0.00017398923\n",
      "Epoch 403, change: 0.00011686178\n",
      "Epoch 404, change: 0.00016218262\n",
      "Epoch 405, change: 0.00013252484\n",
      "Epoch 406, change: 0.00012186283\n",
      "Epoch 407, change: 0.00023066897\n",
      "Epoch 408, change: 0.0001422838\n",
      "Epoch 409, change: 0.00017142146\n",
      "Epoch 410, change: 0.00012307856\n",
      "Epoch 411, change: 0.00017083072\n",
      "Epoch 412, change: 0.00013287252\n",
      "Epoch 413, change: 0.00013481683\n",
      "Epoch 414, change: 0.00018218799\n",
      "Epoch 415, change: 0.00014752909\n",
      "Epoch 416, change: 0.0001267261\n",
      "Epoch 417, change: 0.00014673026\n",
      "Epoch 418, change: 0.00016228794\n",
      "Epoch 419, change: 0.0001258574\n",
      "Epoch 420, change: 0.00014655611\n",
      "Epoch 421, change: 0.00016975455\n",
      "Epoch 422, change: 0.00013238721\n",
      "Epoch 423, change: 0.00013846392\n",
      "Epoch 424, change: 0.00017815895\n",
      "Epoch 425, change: 0.00013551246\n",
      "Epoch 426, change: 0.00016496298\n",
      "Epoch 427, change: 0.00013085896\n",
      "Epoch 428, change: 0.00012405129\n",
      "Epoch 429, change: 0.00012974707\n",
      "Epoch 430, change: 0.00017437314\n",
      "Epoch 431, change: 0.00012547524\n",
      "Epoch 432, change: 0.00013516458\n",
      "Epoch 433, change: 0.00021247014\n",
      "Epoch 434, change: 0.00012274843\n",
      "Epoch 435, change: 0.00016426704\n",
      "Epoch 436, change: 0.0001244678\n",
      "Epoch 437, change: 0.00016048132\n",
      "Epoch 438, change: 0.00014259601\n",
      "Epoch 439, change: 0.00014169388\n",
      "Epoch 440, change: 0.00017145627\n",
      "Epoch 441, change: 0.00013134463\n",
      "Epoch 442, change: 0.00013314978\n",
      "Epoch 443, change: 0.000181355\n",
      "Epoch 444, change: 0.00014030412\n",
      "Epoch 445, change: 0.00016919905\n",
      "Epoch 446, change: 0.00012304394\n",
      "Epoch 447, change: 0.00013247285\n",
      "Epoch 448, change: 0.00012700392\n",
      "Epoch 449, change: 0.00016777476\n",
      "Epoch 450, change: 0.00016023901\n",
      "Epoch 451, change: 0.00014396817\n",
      "Epoch 452, change: 0.00017732415\n",
      "Epoch 453, change: 0.00013002471\n",
      "Epoch 454, change: 0.00016065662\n",
      "Epoch 455, change: 0.00013711004\n",
      "Epoch 456, change: 0.00014787585\n",
      "Epoch 457, change: 0.00014707685\n",
      "Epoch 458, change: 0.00012203742\n",
      "Epoch 459, change: 0.00021608261\n",
      "Epoch 460, change: 0.00013387953\n",
      "Epoch 461, change: 0.00010533265\n",
      "Epoch 462, change: 0.00018427067\n",
      "Epoch 463, change: 0.0001405824\n",
      "Epoch 464, change: 0.00016374624\n",
      "Epoch 465, change: 0.00015155766\n",
      "Epoch 466, change: 0.00016204677\n",
      "Epoch 467, change: 0.00014468201\n",
      "Epoch 468, change: 0.00017816106\n",
      "Epoch 469, change: 0.00016169832\n",
      "Epoch 470, change: 0.00014016597\n",
      "Epoch 471, change: 0.00011950193\n",
      "Epoch 472, change: 0.00011328606\n",
      "Epoch 473, change: 0.00016457992\n",
      "Epoch 474, change: 0.00022309832\n",
      "Epoch 475, change: 0.00012804523\n",
      "Epoch 476, change: 0.00016888672\n",
      "Epoch 477, change: 0.00014304866\n",
      "Epoch 478, change: 0.00016357367\n",
      "Epoch 479, change: 0.00014547969\n",
      "Epoch 480, change: 0.00014148503\n",
      "Epoch 481, change: 0.00015023763\n",
      "Epoch 482, change: 0.00013481735\n",
      "Epoch 483, change: 0.00021754198\n",
      "Epoch 484, change: 0.00013210873\n",
      "Epoch 485, change: 0.00015728788\n",
      "Epoch 486, change: 0.00014488956\n",
      "Epoch 487, change: 0.00015596767\n",
      "Epoch 488, change: 0.00012519807\n",
      "Epoch 489, change: 0.0001549603\n",
      "Epoch 490, change: 0.00013103172\n",
      "Epoch 491, change: 0.00015120993\n",
      "Epoch 492, change: 0.00013398449\n",
      "Epoch 493, change: 0.00014398545\n",
      "Epoch 494, change: 0.00020642822\n",
      "Epoch 495, change: 0.00011905047\n",
      "Epoch 496, change: 0.00012127357\n",
      "Epoch 497, change: 0.00017027553\n",
      "Epoch 498, change: 0.00013104948\n",
      "Epoch 499, change: 0.00014711266\n",
      "max_iter reached after 158 secondsEpoch 500, change: 0.00012773361\n",
      "\n",
      "\n",
      "Accuracy: 0.7514\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Buzzfeed News       0.57      0.55      0.56      1000\n",
      "               CNN       0.66      0.70      0.68      1000\n",
      "         Economist       0.85      0.93      0.89      1000\n",
      "          Fox News       0.76      0.67      0.71      1000\n",
      "            People       0.81      0.89      0.85      1000\n",
      "          Politico       0.62      0.70      0.66      1000\n",
      "           Reuters       0.85      0.85      0.85      1000\n",
      "          The Hill       0.84      0.74      0.79      1000\n",
      "The New York Times       0.78      0.69      0.74      1000\n",
      "              Vice       0.78      0.79      0.79      1000\n",
      "\n",
      "          accuracy                           0.75     10000\n",
      "         macro avg       0.75      0.75      0.75     10000\n",
      "      weighted avg       0.75      0.75      0.75     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "print(\"➜ fitting multinomial logistic regression …\")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    n_jobs=-1,\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"saga\",   # <── swap lbfgs → saga for built‑in progress\n",
    "    verbose=2        # 0 = silent, 1 = compact, 2 = detailed\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=lbl.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_96f24_row0_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 92.9%, transparent 92.9%);\n",
       "}\n",
       "#T_96f24_row1_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 88.9%, transparent 88.9%);\n",
       "}\n",
       "#T_96f24_row2_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 84.6%, transparent 84.6%);\n",
       "}\n",
       "#T_96f24_row3_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 79.2%, transparent 79.2%);\n",
       "}\n",
       "#T_96f24_row4_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 73.9%, transparent 73.9%);\n",
       "}\n",
       "#T_96f24_row5_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 70.5%, transparent 70.5%);\n",
       "}\n",
       "#T_96f24_row6_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 70.3%, transparent 70.3%);\n",
       "}\n",
       "#T_96f24_row7_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 69.4%, transparent 69.4%);\n",
       "}\n",
       "#T_96f24_row8_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 67.2%, transparent 67.2%);\n",
       "}\n",
       "#T_96f24_row9_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #66c2a5 54.5%, transparent 54.5%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_96f24\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_96f24_level0_col0\" class=\"col_heading level0 col0\" >publication</th>\n",
       "      <th id=\"T_96f24_level0_col1\" class=\"col_heading level0 col1\" >n_test</th>\n",
       "      <th id=\"T_96f24_level0_col2\" class=\"col_heading level0 col2\" >correct</th>\n",
       "      <th id=\"T_96f24_level0_col3\" class=\"col_heading level0 col3\" >accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row0\" class=\"row_heading level0 row0\" >2</th>\n",
       "      <td id=\"T_96f24_row0_col0\" class=\"data row0 col0\" >Economist</td>\n",
       "      <td id=\"T_96f24_row0_col1\" class=\"data row0 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row0_col2\" class=\"data row0 col2\" >929</td>\n",
       "      <td id=\"T_96f24_row0_col3\" class=\"data row0 col3\" >0.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row1\" class=\"row_heading level0 row1\" >4</th>\n",
       "      <td id=\"T_96f24_row1_col0\" class=\"data row1 col0\" >People</td>\n",
       "      <td id=\"T_96f24_row1_col1\" class=\"data row1 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row1_col2\" class=\"data row1 col2\" >889</td>\n",
       "      <td id=\"T_96f24_row1_col3\" class=\"data row1 col3\" >0.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row2\" class=\"row_heading level0 row2\" >6</th>\n",
       "      <td id=\"T_96f24_row2_col0\" class=\"data row2 col0\" >Reuters</td>\n",
       "      <td id=\"T_96f24_row2_col1\" class=\"data row2 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row2_col2\" class=\"data row2 col2\" >846</td>\n",
       "      <td id=\"T_96f24_row2_col3\" class=\"data row2 col3\" >0.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row3\" class=\"row_heading level0 row3\" >9</th>\n",
       "      <td id=\"T_96f24_row3_col0\" class=\"data row3 col0\" >Vice</td>\n",
       "      <td id=\"T_96f24_row3_col1\" class=\"data row3 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row3_col2\" class=\"data row3 col2\" >792</td>\n",
       "      <td id=\"T_96f24_row3_col3\" class=\"data row3 col3\" >0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row4\" class=\"row_heading level0 row4\" >7</th>\n",
       "      <td id=\"T_96f24_row4_col0\" class=\"data row4 col0\" >The Hill</td>\n",
       "      <td id=\"T_96f24_row4_col1\" class=\"data row4 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row4_col2\" class=\"data row4 col2\" >739</td>\n",
       "      <td id=\"T_96f24_row4_col3\" class=\"data row4 col3\" >0.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_96f24_row5_col0\" class=\"data row5 col0\" >Politico</td>\n",
       "      <td id=\"T_96f24_row5_col1\" class=\"data row5 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row5_col2\" class=\"data row5 col2\" >705</td>\n",
       "      <td id=\"T_96f24_row5_col3\" class=\"data row5 col3\" >0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row6\" class=\"row_heading level0 row6\" >1</th>\n",
       "      <td id=\"T_96f24_row6_col0\" class=\"data row6 col0\" >CNN</td>\n",
       "      <td id=\"T_96f24_row6_col1\" class=\"data row6 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row6_col2\" class=\"data row6 col2\" >703</td>\n",
       "      <td id=\"T_96f24_row6_col3\" class=\"data row6 col3\" >0.703000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_96f24_row7_col0\" class=\"data row7 col0\" >The New York Times</td>\n",
       "      <td id=\"T_96f24_row7_col1\" class=\"data row7 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row7_col2\" class=\"data row7 col2\" >694</td>\n",
       "      <td id=\"T_96f24_row7_col3\" class=\"data row7 col3\" >0.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row8\" class=\"row_heading level0 row8\" >3</th>\n",
       "      <td id=\"T_96f24_row8_col0\" class=\"data row8 col0\" >Fox News</td>\n",
       "      <td id=\"T_96f24_row8_col1\" class=\"data row8 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row8_col2\" class=\"data row8 col2\" >672</td>\n",
       "      <td id=\"T_96f24_row8_col3\" class=\"data row8 col3\" >0.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96f24_level0_row9\" class=\"row_heading level0 row9\" >0</th>\n",
       "      <td id=\"T_96f24_row9_col0\" class=\"data row9 col0\" >Buzzfeed News</td>\n",
       "      <td id=\"T_96f24_row9_col1\" class=\"data row9 col1\" >1000</td>\n",
       "      <td id=\"T_96f24_row9_col2\" class=\"data row9 col2\" >545</td>\n",
       "      <td id=\"T_96f24_row9_col3\" class=\"data row9 col3\" >0.545000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x347beb140>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ❶ Confusion‑matrix rows = true labels, cols = predicted labels\n",
    "cm = confusion_matrix(y_test, y_pred, labels=range(len(lbl.classes_)))\n",
    "\n",
    "# ❷ Diagonal elements are “hits” for each class\n",
    "hits          = cm.diagonal()\n",
    "total_true    = cm.sum(axis=1)\n",
    "acc_per_class = hits / total_true\n",
    "\n",
    "acc_df = pd.DataFrame({\n",
    "    \"publication\": lbl.classes_,\n",
    "    \"n_test\":      total_true,\n",
    "    \"correct\":     hits,\n",
    "    \"accuracy\":    acc_per_class.round(3)\n",
    "}).sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "display(acc_df.style.bar(subset=[\"accuracy\"], vmin=0, vmax=1, color='#66c2a5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PosixPath' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/gensim/utils.py:763\u001b[0m, in \u001b[0;36mSaveLoad.save\u001b[0;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[43m_pickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    764\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m object\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mpickle\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[1;32m      2\u001b[0m MODEL_DIR \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m); MODEL_DIR\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mw2v_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnews_w2v.model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(clf, MODEL_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogreg.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(lbl, \u001b[38;5;28mopen\u001b[39m(MODEL_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_encoder.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/gensim/models/word2vec.py:1923\u001b[0m, in \u001b[0;36mWord2Vec.save\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the model.\u001b[39;00m\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;124;03m    This saved model can be loaded again using :func:`~gensim.models.word2vec.Word2Vec.load`, which supports\u001b[39;00m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;124;03m    online training and getting vectors for vocabulary words.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \n\u001b[1;32m   1922\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1923\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWord2Vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/gensim/utils.py:766\u001b[0m, in \u001b[0;36mSaveLoad.save\u001b[0;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    764\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m object\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# `fname_or_handle` does not have write attribute\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparately\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/gensim/utils.py:604\u001b[0m, in \u001b[0;36mSaveLoad._smart_save\u001b[0;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_smart_save\u001b[39m(\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;28mself\u001b[39m, fname,\n\u001b[1;32m    577\u001b[0m         separately\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sep_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, ignore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfrozenset\u001b[39m(), pickle_protocol\u001b[38;5;241m=\u001b[39mPICKLE_PROTOCOL,\n\u001b[1;32m    578\u001b[0m     ):\n\u001b[1;32m    579\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the object to a file. Used internally by :meth:`gensim.utils.SaveLoad.save()`.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \n\u001b[1;32m    581\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    602\u001b[0m \n\u001b[1;32m    603\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 604\u001b[0m     compress, subname \u001b[38;5;241m=\u001b[39m \u001b[43mSaveLoad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adapt_by_suffix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m     restores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_specials(\n\u001b[1;32m    607\u001b[0m         fname, separately, sep_limit, ignore, pickle_protocol, compress, subname,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/gensim/utils.py:572\u001b[0m, in \u001b[0;36mSaveLoad._adapt_by_suffix\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_adapt_by_suffix\u001b[39m(fname):\n\u001b[1;32m    559\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get compress setting and filename for numpy file compression.\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    570\u001b[0m \n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     compress, suffix \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpz\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m fname\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bz2\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compress, \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args \u001b[38;5;241m+\u001b[39m (suffix,))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "import joblib, pickle, pathlib\n",
    "MODEL_DIR = pathlib.Path(\"models\"); MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "w2v_model.save(MODEL_DIR / \"news_w2v.model\")\n",
    "joblib.dump(clf, MODEL_DIR / \"logreg.pkl\")\n",
    "pickle.dump(lbl, open(MODEL_DIR / \"label_encoder.pkl\", \"wb\"))\n",
    "print(\"Models saved to\", MODEL_DIR.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
