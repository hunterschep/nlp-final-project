{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f35d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9b6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all-the-news-2-1-SMALL-CLEANED.csv\")\n",
    "# Define features and labels\n",
    "X = df[\"clean_article\"]         # The news articles\n",
    "y = df[\"publication\"]     # The publishers (labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e59ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Strategy: most_frequent ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 0.03991203308105469\n",
      "score_time: 0.19888815879821778\n",
      "test_accuracy: 0.1\n",
      "test_precision_macro: 0.01\n",
      "test_recall_macro: 0.1\n",
      "test_f1_macro: 0.01818181818181818\n",
      "\n",
      "--- Strategy: stratified ---\n",
      "fit_time: 0.037605571746826175\n",
      "score_time: 0.22803821563720703\n",
      "test_accuracy: 0.09793333333333333\n",
      "test_precision_macro: 0.09794154913764777\n",
      "test_recall_macro: 0.09793333333333333\n",
      "test_f1_macro: 0.09793363560726645\n",
      "\n",
      "--- Strategy: uniform ---\n",
      "fit_time: 0.03570680618286133\n",
      "score_time: 0.22003440856933593\n",
      "test_accuracy: 0.10183333333333333\n",
      "test_precision_macro: 0.10183089007818288\n",
      "test_recall_macro: 0.10183333333333333\n",
      "test_f1_macro: 0.10182949004305222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update scoring metrics for multiclass classification using \"macro\" averaging\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "# Loop through the dummy classifier strategies:\n",
    "# - \"most_frequent\": always predicts the most common class.\n",
    "# - \"stratified\": random predictions following the training set's class distribution.\n",
    "# - \"uniform\": completely random predictions.\n",
    "for strategy in [\"most_frequent\", \"stratified\", \"uniform\"]:\n",
    "    print(f\"--- Strategy: {strategy} ---\")\n",
    "    \n",
    "    # Initialize the dummy classifier with the current strategy\n",
    "    dummy_classifier = DummyClassifier(strategy=strategy, random_state=42)\n",
    "    \n",
    "    # Run 5-fold cross-validation\n",
    "    scores = cross_validate(dummy_classifier, X, y, cv=5, scoring=scoring_metrics)\n",
    "    \n",
    "    # Print the mean of each scoring metric across folds\n",
    "    for metric, score in scores.items():\n",
    "        print(f\"{metric}: {score.mean()}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
