{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c13c582c",
   "metadata": {},
   "source": [
    "#### Baselines \n",
    "\n",
    "Trying out some simple baselines and a rule based classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f35d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import re, random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9b6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/all-the-news-2-1-SMALL-CLEANED.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# Define features and labels\n",
    "X = df[\"clean_article\"]         # The news articles\n",
    "y = df[\"publication\"]     # The publishers (labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e59ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Strategy: most_frequent ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time: 0.02360363006591797\n",
      "score_time: 0.12673234939575195\n",
      "test_accuracy: 0.1\n",
      "test_precision_macro: 0.01\n",
      "test_recall_macro: 0.1\n",
      "test_f1_macro: 0.01818181818181818\n",
      "\n",
      "--- Strategy: stratified ---\n",
      "fit_time: 0.022503185272216796\n",
      "score_time: 0.14541869163513182\n",
      "test_accuracy: 0.0982\n",
      "test_precision_macro: 0.09821202435466034\n",
      "test_recall_macro: 0.09820000000000001\n",
      "test_f1_macro: 0.09819609169624727\n",
      "\n",
      "--- Strategy: uniform ---\n",
      "fit_time: 0.02249875068664551\n",
      "score_time: 0.14110960960388183\n",
      "test_accuracy: 0.10264999999999999\n",
      "test_precision_macro: 0.10261707377007004\n",
      "test_recall_macro: 0.10264999999999999\n",
      "test_f1_macro: 0.10262713172068871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update scoring metrics for multiclass classification using \"macro\" averaging\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "# Loop through the dummy classifier strategies:\n",
    "# - \"most_frequent\": always predicts the most common class.\n",
    "# - \"stratified\": random predictions following the training set's class distribution.\n",
    "# - \"uniform\": completely random predictions.\n",
    "for strategy in [\"most_frequent\", \"stratified\", \"uniform\"]:\n",
    "    print(f\"--- Strategy: {strategy} ---\")\n",
    "    \n",
    "    # Initialize the dummy classifier with the current strategy\n",
    "    dummy_classifier = DummyClassifier(strategy=strategy, random_state=42)\n",
    "    \n",
    "    # Run 5-fold cross-validation\n",
    "    scores = cross_validate(dummy_classifier, X, y, cv=5, scoring=scoring_metrics)\n",
    "    \n",
    "    # Print the mean of each scoring metric across folds\n",
    "    for metric, score in scores.items():\n",
    "        print(f\"{metric}: {score.mean()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6670fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random\n",
    "\n",
    "class FewRuleClassifier:\n",
    "    def __init__(self, seed=None):\n",
    "        self.pubs = [\n",
    "            \"The New York Times\",\"The Hill\",\"People\",\"CNN\",\"Vice\",\n",
    "            \"Fox News\",\"BuzzFeed News\",\"Politico\",\"The Economist\",\"Reuters\"\n",
    "        ]\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "\n",
    "    def classify(self, text):\n",
    "\n",
    "        # 1) Reuters — matches \"(Reuters) –\" or CITY – at top\n",
    "        if re.match(r'.{0,40}\\(Reuters\\)\\s+[–-]', text) or \\\n",
    "           re.match(r'^[A-Z][A-Z ]{2,30}[–-]', text):\n",
    "            return \"Reuters\"\n",
    "\n",
    "        # 2) The Economist — ≥3 distinct Brit-spellings\n",
    "        brit_words = re.findall(\n",
    "            r'\\b(colou?r|organis|recognis|analys|centre|defence|licence)\\w*\\b',\n",
    "            text.lower()\n",
    "        )\n",
    "        if len(set(brit_words)) >= 3:\n",
    "            return \"The Economist\"\n",
    "\n",
    "        # 3) People — lots of “!” *and* short sentences\n",
    "        words = re.findall(r'\\w+', text)\n",
    "        sents = [s for s in re.split(r'[.!?]+', text) if s.strip()]\n",
    "        if words:\n",
    "            exc_ratio = text.count('!') / len(words)\n",
    "            avg_sent  = len(words) / len(sents) if sents else 99\n",
    "            if exc_ratio > 0.015 and avg_sent < 15:\n",
    "                return \"People\"\n",
    "\n",
    "        # 4) fallback: pure uniform random\n",
    "        return random.choice(self.pubs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d12add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.08207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     BuzzFeed News       0.00      0.00      0.00         0\n",
      "     Buzzfeed News       0.00      0.00      0.00     10000\n",
      "               CNN       0.10      0.10      0.10     10000\n",
      "         Economist       0.00      0.00      0.00     10000\n",
      "          Fox News       0.10      0.10      0.10     10000\n",
      "            People       0.12      0.13      0.12     10000\n",
      "          Politico       0.10      0.10      0.10     10000\n",
      "           Reuters       0.10      0.10      0.10     10000\n",
      "     The Economist       0.00      0.00      0.00         0\n",
      "          The Hill       0.10      0.10      0.10     10000\n",
      "The New York Times       0.10      0.10      0.10     10000\n",
      "              Vice       0.10      0.10      0.10     10000\n",
      "\n",
      "          accuracy                           0.08    100000\n",
      "         macro avg       0.07      0.07      0.07    100000\n",
      "      weighted avg       0.08      0.08      0.08    100000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gpete\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = FewRuleClassifier()\n",
    "preds = [clf.classify(txt) for txt in df[\"clean_article\"]]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Accuracy:\", accuracy_score(df[\"publication\"], preds))\n",
    "print(classification_report(df[\"publication\"], preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
